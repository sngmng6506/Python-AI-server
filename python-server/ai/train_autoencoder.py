import os
import sys
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.onnx
from pathlib import Path
import zipfile
import json

# Utils import
sys.path.append(os.path.join(os.path.dirname(__file__), 'usad'))
from utils import get_default_device, to_device


class TimeSeriesWindowDataset(Dataset):
    """ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìœˆë„ìš°ë¡œ ë³€í™˜í•˜ëŠ” Dataset"""
    def __init__(self, data, window_size=5):
        self.window_size = window_size
        self.n_features = data.shape[1]
        
        windows = []
        for i in range(len(data) - window_size + 1):
            window = data[i:i+window_size]  # [window_size, n_features]
            windows.append(window)
        
        self.windows = np.array(windows, dtype=np.float32)
        print(f"ìœˆë„ìš° ìƒì„± ì™„ë£Œ: {len(self.windows)}ê°œ ìœˆë„ìš°, shape: {self.windows[0].shape}")
    
    def __len__(self):
        return len(self.windows)
    
    def __getitem__(self, idx):
        return torch.FloatTensor(self.windows[idx])



class TimeSeriesCNN(nn.Module):
    """
    ì‹œê°„ì¶•ì—ë§Œ 1D CNN ì ìš© (ì„¼ì„œë³„ ë…ë¦½)
    [batch, window_size, n_features] -> [batch, n_features]
    """
    def __init__(self, n_features=25000, window_size=5):
        super().__init__()
        self.n_features = n_features
        self.window_size = window_size
        
        # ğŸ”¥ ì„¼ì„œë³„ ë…ë¦½ Time CNN
        self.conv = nn.Conv1d(
            in_channels=n_features,
            out_channels=n_features,
            kernel_size=window_size,
            stride=1,
            padding=0,
            groups=n_features      # âœ… í•µì‹¬
        )
        # self.bn = nn.BatchNorm1d(n_features)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # x: [batch, window_size, n_features]
        
        # Conv1DëŠ” (B, C, T)
        x = x.permute(0, 2, 1)        # [batch, n_features, window_size]
        
        x = self.conv(x)              # [batch, n_features, 1]
        # x = self.bn(x)
        x = self.relu(x)
        
        x = x.squeeze(-1)             # [batch, n_features]
        return x



class SimpleAutoencoder(nn.Module):
    """
    ê¸°ë³¸ì ì¸ Autoencoder
    ì‹œê°„ì¶•ì— 1D CNN ì ìš© í›„ Autoencoder
    ì…ë ¥: [batch, window_size, n_features]
    ì¶œë ¥: [batch, n_features] - ì„¼ì„œë³„ ì´ìƒì¹˜ ì ìˆ˜
    """
    def __init__(self, window_size=5, n_features=25000, latent_size=100):
        super().__init__()
        self.window_size = window_size
        self.n_features = n_features
        
        # ì‹œê°„ì¶•ì— 1D CNN ì ìš©
        self.time_cnn = TimeSeriesCNN(n_features=n_features, window_size=window_size)
        
        # Autoencoder: ì„¼ì„œ ì°¨ì›ì— ëŒ€í•´ ì ìš©
        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(n_features, n_features // 4),
            nn.ReLU(),
            nn.Linear(n_features // 4, n_features // 8),
            nn.ReLU(),
            nn.Linear(n_features // 8, latent_size),
            nn.ReLU()
        )
        
        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_size, n_features // 8),
            nn.ReLU(),
            nn.Linear(n_features // 8, n_features // 4),
            nn.ReLU(),
            nn.Linear(n_features // 4, n_features),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        """
        Args:
            x: [batch, window_size, n_features]
        Returns:
            sensor_scores: [batch, n_features] - ê° ì„¼ì„œë³„ ì´ìƒì¹˜ ì ìˆ˜
        """
        # 1. ì‹œê°„ì¶•ì— CNN ì ìš©: [batch, window_size, n_features] -> [batch, n_features]
        time_compressed = self.time_cnn(x)
        
        # 2. Autoencoder: [batch, n_features] -> [batch, n_features]
        z = self.encoder(time_compressed)  # [batch, latent_size]
        reconstructed = self.decoder(z)  # [batch, n_features]
        
        # 3. ê° ì„¼ì„œë³„ ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°
        sensor_scores = (time_compressed - reconstructed) ** 2  # [batch, n_features]
        
        return sensor_scores
    
    def training_step(self, batch):
        """í•™ìŠµìš© forward pass"""
        sensor_scores = self.forward(batch)
        # ì „ì²´ ì„¼ì„œì˜ í‰ê·  ì˜¤ì°¨ë¥¼ lossë¡œ ì‚¬ìš©
        loss = sensor_scores.mean()
        return loss
    
    def validation_step(self, batch):
        """ê²€ì¦ìš© forward pass"""
        with torch.no_grad():
            sensor_scores = self.forward(batch)
            loss = sensor_scores.mean()
        return {'val_loss': loss}


def load_data(data_path):
    """ë°ì´í„° ë¡œë“œ"""
    print(f"ë°ì´í„° ë¡œë“œ ì¤‘: {data_path}")
    
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
    
    file_size = os.path.getsize(data_path)
    if file_size == 0:
        raise ValueError(f"ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {data_path}")
    
    print(f"íŒŒì¼ í¬ê¸°: {file_size / (1024**2):.2f} MB")
    
    try:
        data = np.load(data_path, allow_pickle=False)
        
        if 'X' not in data or 'y' not in data:
            raise KeyError("NPZ íŒŒì¼ì— 'X' ë˜ëŠ” 'y' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        X = data['X']
        y = data['y']
        
        if len(X) != len(y):
            raise ValueError(f"Xì™€ yì˜ ê¸¸ì´ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: X={len(X)}, y={len(y)}")
        
        print(f"ë°ì´í„° shape: X={X.shape}, y={y.shape}")
        print(f"ì •ìƒ: {np.sum(y == 0)}, ì´ìƒ: {np.sum(y == 1)}")
        
        return X, y
        
    except zipfile.BadZipFile as e:
        print(f"\nâŒ NPZ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
        raise
    except Exception as e:
        print(f"\nâŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise


def prepare_training_data(X, y, window_size=5, train_ratio=0.8):
    """í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©)"""
    normal_indices = np.where(y == 0)[0]
    X_normal = X[normal_indices]
    
    print(f"\nì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©: {len(X_normal)} ì‹œì ")
    
    split_idx = int(len(X_normal) * train_ratio)
    X_train = X_normal[:split_idx]
    X_val = X_normal[split_idx:]
    
    print(f"Train: {len(X_train)} ì‹œì , Val: {len(X_val)} ì‹œì ")
    
    train_dataset = TimeSeriesWindowDataset(X_train, window_size=window_size)
    val_dataset = TimeSeriesWindowDataset(X_val, window_size=window_size)
    
    return train_dataset, val_dataset


def print_gpu_memory(stage=""):
    """GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        max_allocated = torch.cuda.max_memory_allocated() / 1024**3
        print(f"GPU ë©”ëª¨ë¦¬ {stage}: í• ë‹¹={allocated:.2f} GB, ì˜ˆì•½={reserved:.2f} GB, ìµœëŒ€={max_allocated:.2f} GB")


def train_autoencoder(
    train_dataset,
    val_dataset,
    window_size=5,
    n_features=25000,
    latent_size=100,
    epochs=50,
    batch_size=1,
    learning_rate=1e-3
):
    """Autoencoder ëª¨ë¸ í•™ìŠµ"""
    device = get_default_device()
    print(f"\nì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"GPU ì´ ë©”ëª¨ë¦¬: {total_memory:.2f} GB")
        print_gpu_memory("(ì´ˆê¸°)")
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True,
        pin_memory=False,
        num_workers=0
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False,
        pin_memory=False,
        num_workers=0
    )
    
    model = SimpleAutoencoder(
        window_size=window_size,
        n_features=n_features,
        latent_size=latent_size
    )
    model = model.to(device)
    
    print_gpu_memory("(ëª¨ë¸ ìƒì„± í›„)")
    
    total_params = sum(p.numel() for p in model.parameters())
    model_size_mb = total_params * 4 / (1024**2)
    
    print(f"\nëª¨ë¸ êµ¬ì¡°:")
    print(f"  ì…ë ¥: [batch, {window_size}, {n_features}]")
    print(f"  Time CNN: ì‹œê°„ì¶• ì••ì¶• [{window_size} -> 1] -> [batch, {n_features}]")
    print(f"  Encoder: {n_features} -> {n_features // 4} -> {n_features // 8} -> {latent_size}")
    print(f"  Decoder: {latent_size} -> {n_features // 8} -> {n_features // 4} -> {n_features}")
    print(f"  ì¶œë ¥: [batch, {n_features}] - ì„¼ì„œë³„ ì´ìƒì¹˜ ì ìˆ˜")
    print(f"  ì´ íŒŒë¼ë¯¸í„°: {total_params:,} ({model_size_mb:.2f} MB)")
    
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    
    history = []
    total_batches = len(train_loader)
    print(f"\ní•™ìŠµ ì‹œì‘ (Epochs: {epochs}, Batch Size: {batch_size})...")
    print("=" * 60)
    
    for epoch in range(epochs):
        model.train()
        epoch_loss_sum = 0.0
        batch_count = 0
        
        for batch_idx, batch in enumerate(train_loader):
            batch = to_device(batch, device)
            
            loss = model.training_step(batch)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            
            epoch_loss_sum += loss.item()
            batch_count += 1
            
            if (batch_idx + 1) % max(1, total_batches // 10) == 0 or (batch_idx + 1) == total_batches:
                progress = (batch_idx + 1) / total_batches * 100
                avg_loss = epoch_loss_sum / batch_count
                print(f"  Epoch [{epoch+1}/{epochs}] [{batch_idx+1}/{total_batches}] "
                      f"({progress:.1f}%) - Loss: {avg_loss:.4f}")
        
        model.eval()
        val_outputs = []
        with torch.no_grad():
            for batch in val_loader:
                batch = to_device(batch, device)
                val_outputs.append(model.validation_step(batch))
        
        val_losses = [x['val_loss'] for x in val_outputs]
        epoch_val_loss = torch.stack(val_losses).mean().item()
        history.append({'val_loss': epoch_val_loss})
        
        print(f"  Epoch [{epoch+1}/{epochs}] ì™„ë£Œ - "
              f"Train Loss: {epoch_loss_sum/batch_count:.4f}, "
              f"Val Loss: {epoch_val_loss:.4f}")
        print("-" * 60)
    
    print_gpu_memory("(í•™ìŠµ ì™„ë£Œ í›„)")
    return model, history


def convert_to_onnx(model, output_path, window_size=5, n_features=25000):
    """ONNX ë³€í™˜"""
    print(f"\nONNX ë³€í™˜ ì¤‘...")
    
    model.eval()
    model = model.cpu()
    
    dummy_input = torch.randn(1, window_size, n_features, dtype=torch.float32)
    print(f"ì…ë ¥ shape: {dummy_input.shape}")
    
    with torch.no_grad():
        try:
            _ = model(dummy_input)
            print("âœ“ ëª¨ë¸ ê²€ì¦ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ê²€ì¦ ì¤‘ ê²½ê³ : {e}")
    
    try:
        torch.onnx.export(
            model,
            dummy_input,
            output_path,
            input_names=['input'],
            output_names=['sensor_scores'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'sensor_scores': {0: 'batch_size'}
            },
            opset_version=13,
            do_constant_folding=True,
            verbose=False
        )
        
        file_size = os.path.getsize(output_path) / (1024**2)
        print(f"ONNX ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
        
    except Exception as e:
        print(f"âŒ ONNX ë³€í™˜ ì‹¤íŒ¨: {e}")
        raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ê¸°ë³¸ Autoencoder ëª¨ë¸ í•™ìŠµ (ì„¼ì„œë³„ ì´ìƒì¹˜ ì¶œë ¥)")
    print("=" * 60)
    
    base_dir = Path(__file__).parent.parent
    data_path = base_dir / "data" / "data" / "timeseries_test.npz"
    model_dir = base_dir / "ai" / "models"
    model_dir.mkdir(exist_ok=True, parents=True)
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    WINDOW_SIZE = 5
    N_FEATURES = 25000
    LATENT_SIZE = 100
    EPOCHS = 3
    BATCH_SIZE = 64
    LEARNING_RATE = 1e-3
    
    # ë°ì´í„° ë¡œë“œ
    X, y = load_data(data_path)
    train_dataset, val_dataset = prepare_training_data(X, y, window_size=WINDOW_SIZE)
    
    # ëª¨ë¸ í•™ìŠµ
    model, history = train_autoencoder(
        train_dataset,
        val_dataset,
        window_size=WINDOW_SIZE,
        n_features=N_FEATURES,
        latent_size=LATENT_SIZE,
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        learning_rate=LEARNING_RATE
    )
    
    # PyTorch ëª¨ë¸ ì €ì¥
    pytorch_model_path = model_dir / "autoencoder_model.pth"
    torch.save(model.state_dict(), pytorch_model_path)
    print(f"\nPyTorch ëª¨ë¸ ì €ì¥: {pytorch_model_path}")
    
    # ONNX ë³€í™˜
    onnx_model_path = model_dir / "autoencoder_model.onnx"
    convert_to_onnx(
        model,
        onnx_model_path,
        window_size=WINDOW_SIZE,
        n_features=N_FEATURES
    )
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        "model_type": "SimpleAutoencoder",
        "window_size": WINDOW_SIZE,
        "n_features": N_FEATURES,
        "latent_size": LATENT_SIZE,
        "input_shape": [WINDOW_SIZE, N_FEATURES],
        "output_shape": [N_FEATURES],
        "pytorch_model": str(pytorch_model_path),
        "onnx_model": str(onnx_model_path),
        "training_history": {
            "final_val_loss": float(history[-1]['val_loss'])
        }
    }
    
    metadata_path = model_dir / "autoencoder_metadata.json"
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"\në©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
    print("\n" + "=" * 60)
    print("í•™ìŠµ ë° ë³€í™˜ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
